\section{Lecture 8}
\subsection{Bessel and Parseval}
\begin{lemma}
    Let $V$ be a vector space with an inner product; let $v_1, v_2, ... \in V$ be an orthonormal set. Then, let $v \in V$. Then,
    \begin{enumerate}
        \item (Bessel's Inequality)
        $$\norm{v}^2 \ge \sum_i^{N \le \dim V} \abs{\langle v, v_i \rangle}^2$$
        \item (Parseval's Theorem) If $\{ v_i \}$ is complete, then
        $$\norm{v}^2 = \sum_i^{\dim V} \abs{\langle v, v_i \rangle}^2$$
    \end{enumerate}
\end{lemma}
\begin{proof}
    From Lemma 5.7,
    \begin{align}
        (v - P_Wv) \perp w \mid \forall w \in W:= \text{span} \{v_1, v_2, ..., v_N\} \mid \forall N \in \mathbb{Z}
    \end{align}
    So, $(v - P_Wv) \perp P_W v$. Then, by the Pythagorean Theorem,
    \begin{align}
        \norm{v}^2 &= \norm{P_Wv}^2 + \norm{v - P_Wv}^2 \ge \norm{P_Wv}^2\\
        \implies \norm{v}^2 &\ge \norm{P_Wv}^2
    \end{align}
    So, recall (5.13), and write the right side as
    \begin{align}
        \left\langle \sum_{i=1}^N \langle v, v_i \rangle v_i, \sum_{j=1}^N \langle v, v_j \rangle v_j \right\rangle
    \end{align}
    But, when $i \ne j$, this goes to $0$ due to orthonormality. So,
    \begin{align}
        (8.5) &= \left\langle \sum_{i=1}^N \langle v, v_i \rangle v_i, \sum_{i=1}^N \langle v, v_i \rangle v_j \right\rangle\\
        &= \sum_{i=1}^N \langle v, v_i \rangle \overline{\langle v, v_i \rangle} = \sum_{i=1}^N \abs{\langle v, v_i \rangle}^2
    \end{align}
    Thus, 
    \begin{align}
        \norm{v}^2 &\ge (\norm{P_Wv}^2 = \sum_{i=1}^N \abs{\langle v, v_i \rangle}^2 )\\
        \implies \norm{v}^2 &\ge \sum_{i=1}^N \abs{\langle v, v_i \rangle}^2
    \end{align}
    In particular, as $N \to \infty$,
    \begin{align}
        \norm{v}^2 &= \sum_{i=1}^\infty \abs{\langle v, v_i \rangle}^2
    \end{align}
    Recall that we assume that $\{ v \}$ is complete. So, by definition,
    \begin{align}
        v = \lim_{N \to \infty} P_W v
    \end{align}
    that is, these approximations converge back to $v$ as $W \to \text{ completeness}$. By Lemma 6.4,
    \begin{align}
        \lim_{N \to \infty} \norm{P_W v} \to \norm{v}
    \end{align}
    so
    \begin{align}
        \lim_{N \to \infty} \norm{P_W v}^2 \to \norm{v}^2
    \end{align}
    which becomes, by (8.8),
    \begin{align}
        \lim_{N \to \infty} \sum_{i=1}^N \abs{\langle v, v_i \rangle}^2 &\to \norm{v}^2\\
        \implies \norm{v^2} &= \sum_{i=1}^\infty \abs{\langle v, v_i \rangle}^2
    \end{align}
\end{proof}

\subsection{An Example}
Let
\begin{align}
    V = C[0,1] \mid \{ e^{2\pi int} \} \text{ be complete}
\end{align}
We use the second simplest function\footnote{What is the first simplest function?!}
\begin{align}
    v = t
\end{align}
By Bessel,
\begin{align}
    \norm{t}^2 = \sum \abs{\langle t, e^{2\pi int} \rangle}^2
\end{align}
We take the inside and evaluate it
\begin{align}
    \langle t, e^{2\pi int} \rangle = \int_0^1 t \cdot e^{2\pi int} \dd{t}
\end{align}
and by parts it into\footnote{This is not AP Calculus AB so the proof is not going to be copied into these notes.}
\begin{align}
    \dfrac{-1}{2\pi in}
\end{align}
The edge case is at $n=0$, which when we plug into (8.18) yields $\frac{1}{2}$. The left hand side of (8.17) is $\frac{1}{3}$. So,
\begin{align}
    \frac{1}{3} &= (\frac{1}{2})^2 + 2\sum_{n=1}^\infty \frac{1}{4\pi^2 n^2}\\
    \frac{1}{6} &= \sum \frac{1}{\pi^2 n^2}\\
    \frac{\pi^2}{6} &= \sum \frac{1}{n^2}
\end{align}